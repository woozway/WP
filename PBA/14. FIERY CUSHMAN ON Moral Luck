Nigel Warburton, Philosophy Bites Again

FREE WILL,
RESPONSIBILITY,
AND PUNISHMENT

FIERY CUSHMAN ON 
Moral Luck

David Edmonds: Suppose on a Monday, we forgot to show up to a
Philosophy Bites interview and the interviewee was kept hanging
around in a furious mood for an hour. Then suppose, on Tuesday, we
forgot to turn up for a different interview. But this time the interviewee, by
coincidence, also forgot and so wasn’t kept waiting at all. Are we more
culpable for the former omission than the latter? Fiery Cushman is a
psychologist fascinated by philosophy and he’s made a special study of
what’s called ‘moral luck’.

Nigel Warburton: The topic we’re focusing on is moral luck. Could
you begin by saying what moral luck is?

Fiery Cushman: It’s best illustrated with a specific case.
Imagine that, after this interview, you and I went out for a
couple of beers. Then each of us gets into our separate cars to
go home. On your way home, you fall asleep at the wheel and
you run off the road and run into a pile of bushes and get
picked up for drunk driving. (I’ll be generous and assume this
is your first offence, Nigel). I don’t know about the laws in
Britain, but in my home state of Massachusetts you could
expect to receive a $250 fine.

On my way home, I fall asleep and I run off the road and I
hit a person and kill him. In Massachusetts, I could expect 2.5
to 15 years in prison. Those are radically different amounts of
punishment for what amounts to identical behaviour. The
twentieth-century British philosopher, Bernard Williams,
pointed out that in this respect morality seems to depend on
luck. That’s the phenomenon that I’ve been investigating.

NW: So the luck here is whether somebody happens to be by the side of
the road when your car veers off on the pavement?

FC: Exactly.

NW: Now, that’s not the only kind of luck that could be related to
morality. It seems to me a matter of luck that I was born in Britain at a
time of relative peace and not, for instance, in Nazi Germany.

FC: That’s right. Williams sketched out a number of
different ways that luck can impact moral judgements. He
calls the one that I have been focusing on, outcome luck. The
idea is that some chance variable in the world produces
different outcomes based on the same underlying behaviour.

NW: Can you say something about your work: you’re principally a
psychologist investigating philosophical issues . . .

FC: It’s a tremendous benefit to psychology to have
centuries and sometimes millennia of philosophy to draw on.
Philosophers have laid out foundational concepts and, perhaps
most importantly, they’ve identified dilemmas. In other words,
they have found situations where our intuitions in different
cases seem somehow mismatched. And so I have had some
success, I hope, in probing those dilemmas in order to discover
the competing psychological mechanisms, the competing
systems, that make us feel quite literally ‘of two minds’, torn
between one perspective and another.

NW: So we have competing intuitions in the drink-driving case we
were talking about. On the one hand, it’s a matter of luck whether
somebody happens to be on the pavement at the very moment that you veer
off the road. On the other hand, it does feel intuitively right that people
who are drunk and kill people on the way home ought to be severely
punished. And those competing intuitions don’t match.

FC: That’s right. I would put it like this: on the one hand,
it seems absolutely crazy to take a person who ran into a
bush and send them to prison for ten years. On the other
hand, it seems equally crazy to take someone who killed a
person and let them off with a $250 ticket. We’ve begun to
articulate the two psychological mechanisms that are
responsible for these competing intuitions. And the surprise
is that, in a sense, they track judgements of wrongness
versus punishment.

So, if you give people these two cases and you ask, ‘How
wrong was Nigel?’, ‘How wrong was Fiery?’, ‘How wrong
was their behaviour?’, they will tend to say that the two of us
have engaged in equally wrong behaviour. If you ask, ‘How
bad is our character?’, they’ll say that we have equally bad
characters.

But when we ask, ‘How much punishment should Nigel get?’
and ‘How much punishment should Fiery get?’, suddenly we
find that the issue of outcomes matters. So part of the
mystery to be explained is why the brain would be designed
with different sets of moral intuitions that lead to different
answers—one for wrongness or character and another one for
punishment?

NW: When you say that people focusing on judgements of wrongness
give the same answer in both cases, that’s not just a hunch, is it? This is
something that you’ve discovered through empirical methods.

FC: Yes, that’s right. We’ve tested literally thousands of
people on the web by giving them hypothetical cases to judge.
Of course, you don’t want to premise your whole argument
on a single scenario, so we give them many different cases that
manipulate people’s intentions and manipulate the outcome
of their behaviour. And then we ask people to make
judgements of wrongness or character or appropriate
punishment.

Now, of course, one concern is whether you can trust what
people say on the Internet. People say all kinds of crazy things.
So, our next study brought people into the lab. We modified
methods used in behavioural economics where people exchange
money in rule-structured games. We introduced accidents into
those games and looked at whether people would punish and
reward even then, based on outcomes. And what we found is
this. If I allocate money to you by the roll of dice, then just that
roll of dice is enough for you to modulate how you’ll reward or
punish me. If the dice come up so that I was very generous to
you, then you’ll sometimes ignore my intent, focus on the dice,
and reward me. Whereas if the dice come up in a way that I end
up being stingy to you, even if I intended to be generous, you’ll
turn around and punish me. So that was a nice confirmation in
the laboratory of our Internet findings.

NW: What’s interesting about your results is that your conclusions are
counterintuitive. I would have expected people’s judgements of wrongness
to match their judgements of punishment, but you found a split. Why do
you think they split?

FC: It’s a really fascinating question, and it’s one that we’ve
put a lot of effort into trying to address. It’s difficult to explain
why outcomes would matter just for punishment, not for
other categories of moral judgement. So, for instance, you
might say that intentions are very difficult to know, you can’t
be sure what somebody’s intentions are, so you use outcomes
as a heuristic. But, of course, outcomes are equally difficult to
know, whether you’re making a judgement of their character
or a judgement of how much punishment they deserve. So
the difficulty is to explain what makes punishment unique,
such that outcomes would matter more in that case.

The hunch that we have is that it might have to do with the
role that punishment plays in teaching people how to behave
in the future.

When you make a judgement of someone’s character,
you’re trying to decide, ‘Should I interact with them?’ You’re
predicting how they’re going to behave in the future. But
when you punish somebody, you’re hoping to actually change
their behaviour. Suppose people just happen to be designed so
that they learn better from being rewarded and punished
based on outcomes, and they learn worse from being
rewarded and punished based on intent. Then you might
expect that over the course of evolution our intuitions about
punishment would become honed to focus on outcomes.

So, we designed an experiment to test the hypothesis that
the way that we punish is matched to the way that we happen
to learn. Suppose you and I are participating in the
experiment. You’re going to be throwing darts at a board and
winning and losing money for me. I’m hoping that you aim for
the good targets, but the trick is that you don’t know which
targets are good for me and which are bad. You’re going to
throw many times, and after each one of your throws I’m
going to be rewarding or punishing you to try to teach you.

So if you aim for a good thing and hit it, I’m going to want
to reward that; if you aim for a bad thing and hit it, I’m going
to want to punish that. Of course, you’re not perfect at
darts—nobody is—and we demand that you call your shots.
That means that, if you say, ‘I’m aiming for green’, and I
know that that’s going to earn me a lot of money, but then
you hit red and that loses me a lot of money, I face a
dilemma. What am I going to do? Am I going to reward you
for your generous intent or am I going to punish you for the
bad outcome?

So we put it to the test. For half the people we adopted the
first strategy. We would always reward or punish based on
what they were aiming at. And for half of the people, we
adopted the second strategy: we would reward and punish
based on what they hit. Here’s what we found: by the end of
the experiment, the second group of people had learned much
better which targets were good and bad. That seems to
indicate that it’s just a feature of the way that we learn, and
that we learn better from outcomes. When we get punished,
we don’t think to ourselves, ‘Oh, gee, I must have had the
wrong intent’; we think, ‘What happened? What did I do?’ So
our punishment judgements seem to be adapted to fit the way
in which we learn.

Professors talk a lot about teachable moments. It’s the
classroom moment when things align in just the right way for
you to convey an important lesson. You can think about
accidents through the same lens. Your child might not have
meant to break the teacup, but it’s a teachable moment. You
have an opportunity to convey a message about what matters
to you, and we seem to have evolved to exploit those
moments.

NW: Perhaps we should introduce a third person to your scenario.
We’ve talked about the two of us. I drive home, veer off the road drunk,
but don’t kill anybody. You drive home, you veer off the road and you kill
somebody. What about David here who is holding the microphone? What
if he drives home completely sober, sees an enemy, deliberately veers off the
road and kills him? How would your approach explain our different
intuitions in those three cases?

FC: I’m glad you asked that question because it highlights an
important issue. Although I’ve been emphasizing the dilemma
of punishment—that outcomes seem to matter—there is also
an uncontroversial element, which is that intent matters
enormously for punishment too. I don’t want to give the
impression that this story is all about outcome. There is lots
of research, including my own, that suggests that David
would be punished very, very severely based in part on his
malicious intent.

That sensitivity to intentions emerges early in childhood,
and grows a lot between the ages of about four and eight. In
fact, the very first experiments in moral psychology, by Jean
Piaget, identify this developmental change. Four-year-olds are
very outcome-based. By the age of eight, they’re much more
intent-based, and that focus on intent continues to play an
important role in the way that you judge punishment for the
rest of your life.

It looks like punishment is a composite of two forces. There
is a developmentally early emerging, and possibly (we need
more evidence for this) innate, reflex that says that if you
caused harm, you deserve punishment. Layered on top of that
is the capacity that reflects intentions, and which appears to
emerge later in development. By the time you’re an adult, the
intent-based capacity is, in fact, the dominant one. It plays the
greater role in determining punishment. Nonetheless, beneath
it, creating these moral luck dilemmas, there is still this
retributive reflex that can push cases around at the margins.

NW: There is a great film by Buñuel called the The Criminal Life of
Archibaldo de la Cruz, in which the central character has malicious
intentions. He tries to kill a number of people, but by chance those people
get killed in other ways just at the point where he’s about to kill them.
Now, he’s got the intent, but not the outcome. What would you say about
that case?

FC: It’s interesting that you ask this. We tested cases that
have just that structure. We have examples of people who
attempt to kill somebody and fail, and that’s the end of the
story. We contrast those scenarios with others in which people
attempt to kill somebody and fail, but coincidently the person
dies. We discovered that if, coincidently, the person dies,
people are more likely to let the attempted murderer off the
hook completely. If the person doesn’t die coincidentally, the
attempted murderer is less likely to get let off the hook.

So this is really curious. What seems to explain it is the
reflex that I mentioned. You have a reflex to find the causally
responsible person and punish them. Thus, if I attempt to kill
you and then coincidently you eat a poisoned salad, our reflex
asks, ‘Where did the poisoned salad come from?’ That process
diverts our attention. Because we are focused on the kitchen,
we ignore the person with the loaded gun who just tried to
shoot you. Whereas, if the salad doesn’t kill you, that reflex
never gets engaged. Thus, that more-developmentally-later-
emerging process, the one that focuses on intent, can direct
attention to the person with the loaded gun, who tried to kill you.

NW: So you’re claiming that we’ve evolved with these competing
intuitions and there are evolutionary explanations for why that should be
so. Let’s say your hypothesis is correct. There is a further question though.
If a pattern of behaviour or judgement has evolved from, say, the
Pleistocene epoch, it doesn’t follow that this behaviour or judgement is a
good thing. People like sweet food because in the Pleistocene we took all
the energy that we could when it was available. But now that’s a bad
thing because people in the twenty-first century become obese. Is there a
parallel here with our views about punishment and culpability?

FC: That’s a wonderful question. The analogy with our diet
is a very good one. Think about that child I mentioned who
broke the teacup, and whose mother can exploit that event as
a teachable moment. In our evolutionary history, she couldn’t
use language; all that she could do was punish the child to
convey the message that broken teacups are bad. In our
evolutionary present, she has another option: she can say,
‘That broken teacup really upset me’, or before the situation
even arose she could say, ‘Here are the rules: no breaking
teacups.’ In an interesting way, language gives us an escape
hatch from this evolutionary dilemma of needing to punish
accidental outcomes. It’s one that, at a normative level, I wish
we might exercise more often.