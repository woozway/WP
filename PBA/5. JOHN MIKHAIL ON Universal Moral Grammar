Nigel Warburton, Philosophy Bites Again

MORALITY

JOHN MIKHAIL ON
Universal Moral Grammar

Nigel Warburton: Most parents know that young children are good
at making moral judgements, particularly on issues of fairness. But how
do they acquire this ability? Is it all a matter of imitation and instruction
picked up in the home and kindergarten, or could there be some kind of
innate or universal moral grammar, a human predisposition to structure
moral judgements in particular ways? John Mikhail suspects that when it
comes to issues of right and wrong, children aren’t just blank slates.

David Edmonds: Today we’re talking about the subject of ‘universal
moral grammar’. That’s a bit of a mouthful. What is universal moral
grammar?

John Mikhail: It is a bit of a mouthful. The basic idea is that
there might be an innate basis to our moral judgements.
When we try to describe what that innate moral knowledge
might be, we’re describing a system of principles or rules that
is perhaps analogous to what linguists who study the innate
basis of language call ‘universal grammar’.

DE: So you’re referring to the work of Noam Chomsky, a linguist based
at the Massachusetts Institute of Technology. Chomsky argues that we all
have an innate linguistic grammar, and that all languages have the same
deep grammatical structure.

JM: Yes, that’s more or less right. Chomsky is probably best
known for the work he did in the 1950s, 1960s, and 1970s in
developing the idea that the way children learn language cannot
be adequately explained by assuming that their knowledge of
grammar is simply internalized from their surroundings—from
the people whom they encounter, their parents, their friends,
and so forth. And the main reason for this conclusion is that
children appear to use grammatical rules and principles that are
neither explicitly taught nor otherwise given to them by their
environment.

DE: And your contention is that morality parallels language in that
way?

JM: My contention is that morality might parallel language in
that way. And I emphasize the word ‘might’ because this is
meant to be an empirical hypothesis; it could be false. More
broadly, my proposal is that we might be able to make
progress in the study of moral judgement by drawing on ideas
that have been useful in other domains like language.

DE: So if the claim that morality has an innate basis is an empirical
one, you must have some evidence, I assume. What’s your evidence?

JM: Yes. There’s actually a lot of evidence that young children
are what I would call ‘intuitive lawyers’. They make moral
judgements in ways that are surprisingly sophisticated, which
seem to rely on the kinds of rules and principles that adults use
in their everyday practice, and even on rules and principles
that legal systems use. For example, three- and four-year-old
children use intent—the actors’ goal or purpose—to distinguish
two acts with the same result. That’s something that virtually
every legal system does as well.

Likewise, four- and five-year-old children draw a distinction
that’s quite similar to the distinction that’s drawn in law
between what are called ‘mistakes of fact’ and ‘mistakes of
law’. Let me give you an example of this distinction. Suppose
someone shoots and kills another person under the mistaken
belief that the other person is a tree stump. Let’s imagine
that the agent is out on a hunting expedition and he turns and
fires his gun, thinking he is shooting at, not a person, but some
object. If his mistake was reasonable, that’s what lawyers would
call a reasonable ‘mistake of fact’. Now consider a second case,
in which someone shoots and kills another person in the
mistaken belief that killing is not wrong. This is a different kind
of mistaken belief. It is a mistake about the norm itself, or what
lawyers would call a ‘mistake of law’.

Ordinary adults would draw an intuitive distinction
between these two cases. The first case could result in a kind
of justification or excuse, or perhaps an acquittal on other
grounds, because the agent lacks the intent necessary to form
a criminal act. We certainly would not think of someone who
makes such an error as a murderer. The second case strikes us
as quite different. It’s not a justification or excuse to say, ‘I just
don’t think killing is wrong.’

Legal systems distinguish cases like these, of course, but
what is interesting and noteworthy is that young children also
apparently draw this distinction; moreover, they appear to
do so in different cultural contexts. That’s the kind of evidence
to which I’m referring when I suggest that young children
are intuitive lawyers, who possess tacit knowledge of an
abstract system of moral rules, or what we are calling a moral
grammar.

DE: But how do you know that kids aren’t picking those rules up from
their parents, either explicitly or just by watching how their parents judge
and behave?

JM: That’s a very good question. The first answer I would
give is that they could be. In this sense, an empiricist theory of
moral learning could turn out to be correct. These are tricky
issues, and the only way to confront them is by studying child
development in detail. Are children actually being taught these
kinds of distinctions or does this behaviour go beyond their
experience? If researchers can line up case after case after case
in which children act like intuitive lawyers—that is, they
display a sense of right and wrong that is sophisticated and
seems to go beyond their experience—then this evidence can
strengthen the argument that there is some kind of innate
basis to their moral judgements.

DE: What about cross-cultural evidence? Presumably, there’s evidence
that morality operates in pretty much the same way in cultures as varied
as those in the United States, India, and China?

JM: Here we have to draw a distinction, right off the bat,
between behaviour and perception. There’s no question that
the anthropological record suggests a wide variety of practices
in the domain of moral behaviour. On the other hand, the
question that we’re considering now is whether intuitive
moral perceptions and judgements—which are only one
component of why people act the way they do—have a shared
basis across cultures. If one keeps this distinction in mind,
then it will be more plausible to conclude that there may be
cross-cultural evidence for a shared moral grammar.

One obvious point to consider in this context concerns the
very notion of human rights. For some time now, people from
different cultures around the world have been able to reach at
least some agreement on basic norms of conduct, despite quite
substantial differences in culture, language, and religious or
philosophical backgrounds. This kind of phenomenon, universal
human rights, has no counterpart in the case of language. What
it suggests is that there may be more uniformity, universality, and
built-in constraint in the moral domain than there is in the case
of natural language.

DE: And yet, some people might say, for example, ‘Well, in Singapore,
they are much less committed to free speech than they are in the United
States. That’s just a fact about their culture.’

JM: Yes. That’s a very important point. The best case for a
shared moral grammar at the level of what is acquired by each
individual is probably not going to involve norms about
freedom of speech or other complicated norms that depend
on institutions. Instead, it will concern the kind of pre-politi-
cal normative principles that one typically finds in fields like
criminal law, contract law, or tort law, basic norms that explain
when it is wrong or permissible to harm one another, what
kinds of harms might be justifiable, what are the obligations
that derive from promises and mutual agreement, and other
similar fact patterns.

DE: So, you’ve got the evidence from children. You’ve got the evidence
from shared cross-cultural moral values. Does that exhaust the empirical
evidence for universal moral grammar?

JM: I don’t think so. Here, again, it’s important to draw a
distinction between the acquired moral grammar possessed by
each individual and what we’re calling universal moral grammar,
which is the supposed innate basis for that acquired grammar.
Let’s just stick for a moment to the acquired moral grammar:
the abstract system of moral rules and principles that each adult
presumably carries around unconsciously in his or her mind.
Well, there are many reasons to infer that each individual
possesses such a system.

One argument to make in this context is what philosophers
call an ‘abductive’ argument. The argument begins from the
observation that ordinary individuals can make moral judge-
ments about brand new situations, situations they’ve never
encountered before. In the law, these are sometimes called
‘cases of first impression’. The fact is that most people can do
this: that is, they are capable of making moral judgements
about these novel fact patterns. The argument for moral
grammar holds that the best explanation of this behaviour
must appeal to some kind of system of rules and principles.
The moral judgements people make are too stable, too
systematic, too widely shared, and too predictable for these
judgements to be made on a case-by-case basis, without the
support or guidance of rules or principles.

DE: Can you explain that a bit more? You’re suggesting that, although
all of us have had different experiences in making moral choices in the
past, when we’re faced with a brand-new case, we reliably and predictably
reach a particular conclusion.

JM: Yes, that’s right. It is often the case that people know the
right thing to do in a given situation, even though they’ve never
encountered that situation. The other point to emphasize here is
that moral judgement is intuitive. For some time, philosophers may
have operated under the mistaken impression that moral judgements
are typically produced by the conscious application of rules and
principles. But that doesn’t seem to be accurate in many situations.
We’re frequently not aware that we’re applying rules or principles
when we make moral judgements. Nonetheless, the cognitive
scientist can, after the fact, explain our moral judgements—or maybe
even before the fact predict our moral judgements—by assuming that
we’re relying on rules or principles.

DE: So give me an example of a new moral case where we are faced
with a choice between various options and where we choose the option
consistent with a rule that we might even be unaware of.

JM: Sure. Some of the best examples concern the so-called
‘trolley problems’. These are moral dilemmas, somewhat
bizarre, and often highly artificial. Yet the surprising fact is that
there appears to be widespread agreement, even around the
world, on the permissible conduct in the given circumstances.

Let me give you two cases. The first case is sometimes
called the ‘bystander problem’. A train is rushing down the
tracks and it’s about to run over and kill five people. There’s a
bystander who is watching this happen, and he is standing next
to a switch. The bystander can throw the switch, which will
turn the train onto a sidetrack and save the five people from
being killed. There’s one person on the sidetrack, however,
and if the train is turned, that one person will be run over and
killed. The moral question is: is it permissible for the by-
stander to turn the train?

That’s the kind of situation that most of us don’t encounter
in our daily life. Yet it turns out that the vast majority of
people have a shared response. They respond in a more or less
utilitarian fashion and say, ‘Yes, it’s permissible to turn the
train.’ In that kind of situation, if there are no better alterna-
tives, then it’s permissible to do something that would result in
one death, rather than five. That’s the better choice under the
circumstances.

The second case might involve a surgeon who has five
patients who are dying; each patient is in need of a different
organ to survive. And the only way to save these five would
be to cut up a healthy individual and distribute her organs to
the five. Would it be permissible to do this, assuming the
healthy individual did not consent? Very few people believe
it would be.

Or imagine an even closer parallel to the first trolley
problem. Suppose the train is rushing towards five people and
the only way to save them would be to throw a heavy man off
a footbridge in front of the train in order to stop it from
crashing into the five. The heavy man would die, but the five
people on the tracks would be saved. Would it be permissible
to throw the man? Again, very few people believe that it would
be, even though they may not be able to explain just why this
case differs from the original bystander problem.

DE: That’s fascinating because in each of these train cases we are given
the option of killing one to save five. But we think it’s acceptable to kill
one person on the side-track in the first scenario, but not the heavy
individual in the second. We draw this distinction, and we may not know
why we draw it.

JM: That’s correct. Beginning in the mid-1990s, my col-
leagues Elizabeth Spelke, Cristina Sorrentino, and I began
studying these kinds of questions experimentally. And in
addition to asking people for their intuitive moral judgements,
we asked them to justify their judgements. We discovered that
people are often incapable of giving an adequate explanation
or justification of their judgements. They often say things like,
‘I don’t know why I decided differently in the second case.’ Or
they might say something self-deprecating like, ‘I know what
I said is not rational, but it’s what I feel nonetheless.’

The critical point, however, is that these judgements can
be explained with reference to principles or rules. For
example, one way to explain the difference between these
cases would be to appeal to the concept of battery. This
simple norm, which one finds in legal systems throughout
the world, prohibits intentionally causing harmful contact
with another person without his or her consent. One key
difference in all of the standard trolley problems, including
the examples I just gave, is that in the permissible cases (such
as the bystander problem) the actor commits battery only as
a side-effect of achieving the good end of saving the five,
whereas in the impermissible cases (such as the transplant or
footbridge problems), the actor necessarily has to commit a
battery as a means to achieve his good end. So, stepping
back, one might say that the moral grammar, at least in part,
consists of ethical rules that are sensitive to whether battery
is being committed as a means to an end, or merely as a
side-effect.

DE: That appears to give us another parallel with language. We might
be able to speak a language fluently, but if we were asked why we follow a
particular rule, why we say the ‘big, blue elephant’ and not the ‘blue, big
elephant’, for example, we might not be able to explain it, and yet
linguists can tell us what rules we’re following.

JM: Yes, that’s correct. In the case of language, the argument
for universal grammar is basically a two-step argument. First,
we have to appeal to unconscious rules to explain linguistic
behaviour. Second, we might appeal to innate knowledge to
explain how those rules are acquired. It’s important not to
conflate those two parts of the argument.

As to the first part, Chomsky’s most famous example is a
nice illustration of what you’re talking about. Take a sentence
like ‘Colourless green ideas sleep furiously.’ Well, that’s a
meaningless sentence. How can an idea be colourless and
green at the same time? What does it mean for an idea to sleep
furiously? The expression has an aspect of poetry to it, but it’s
semantically nonsensical. Nonetheless, Chomsky’s point was
that it’s a well-formed sentence of English, at the level of
syntax.

Contrast this case with another expression, in which the
same five words are read backwards, ‘Furiously sleep ideas
green colourless.’ That’s not a well-formed sentence of
English. Why not? Well, the explanation here might appeal to
an unconscious rule that ordinary speakers of English possess,
which says, in effect, ‘If I encounter a construction that has the
following grammar: adjective, adjective, noun, verb, adverb—
that’s going to seem acceptable to me. Whereas if I encounter
a construction in which the same grammatical categories run
in the opposite direction, that’s not going to be a good
sentence.’ And we might think of the parallel to the moral
case as drawing insight from this situation, in which there
appear to be unconscious rules that explain our perceptual and
cognitive behaviour. We don’t have introspective access to these
rules, but nonetheless, by appealing to these rules, we can
successfully predict and explain people’s moral judgements.

DE: In the last decade or so neuroscience has flourished, and we now
have access to quite sophisticated brain scanning. Does any of this cast
light on whether or not we have universal moral grammar?

JM: Yes, I think it does. All of these areas of research—child
development, anthropology, philosophy of mind, neuroscience,
and so forth—we can think of as supplying more pieces of the
puzzle. No one piece proves the case, but collectively this body
of evidence supports the plausibility of the thesis that human
beings may possess an innate moral grammar.

In the past few years, quite exciting research has begun to
identify the regions of the brain that appear responsible for
various components of moral judgement. An obvious
example to consider here would be—again, appealing to the
law—the difference between what lawyers call mens rea and
actus reus, or the guilty mind and the guilty act. In the
criminal law, you typically need a concurrence of both the
mental state component (the guilty mind) and the action
component (the guilty act) in order to have a completed or
fully fledged crime, which can warrant conviction. Brain
scientists are now starting to find the regions of the brain
that seem to be especially active in the way that we generate
representations of mens rea: that is, of criminal intent or
other mental states. If the moral grammar theory postulates
that this is an important distinction, and this proposal leads
scientists to examine how the brain processes mental state
information and eventually to discover that there are specific
regions of the brain that are primarily responsible for
generating these representations, then that discovery would
tend to support the moral grammar theory a bit more than if
we didn’t possess this evidence.

DE: You say that the question of whether there’s a universal grammar
hasn’t been fully determined yet. But I suspect that you think there is one.
Now, if there is a universal moral grammar and if humans operate on a
set of moral rules, perhaps very sophisticated rules, does that imply that
we could train a computer to operate according to the same principles and
come to the same moral judgements that a human being comes to?

JM: That’s a very interesting question. A couple of points
to bear in mind here; first, the kinds of studies that moral
psychologists have carried out thus far typically deal with very
simple cases. So if you were to ask me, ‘Could we design a
computer that could handle many or most of the moral
problems that we, as individuals or as a society, face in our daily
lives?’ I would answer: ‘I’m sceptical.’ However, if we consider a
more specific question, then the answer might be different.
Suppose you were to say, ‘Here is a set of crimes. Can you
design a computer to make judgements about the permissibility
of the conduct in this small sub-set of cases?’ Well, the answer
there is probably ‘yes’. In fact, we know that in liberal legal
systems the answer almost certainly must be yes. Because the
fact is that liberal legal systems are committed to codifying all
of the criminal acts ahead of time. The principal of legality in
the law says that there’s no crime without law, no punishment
without law, and no retroactive punishment. Liberal societies
such as ours have already accepted the idea that at least some of
our moral life can be codified. And if it can be codified, then, in
principle, a computer could presumably carry out those
operations.

DE: Do you have kids?

JM: I have two children.

DE: What part are you playing in their moral upbringing?

JM: (Laughter). I began working on these ideas before I
had a family and children, and I think I’ve changed my mind
a bit about the importance of instruction and explicit moral
guidance. I used to think that the development of moral
competence was more or less on auto-pilot, so that it was
just going to happen, like growing an arm or a leg. After the
experience of raising children, I don’t think I would so
casually affirm the same thesis anymore. But I still do believe
that there is an innate basis to the sense of right and wrong,
for the reasons I have indicated here and elaborated else-
where in print. And the fact is that my kids and other kids
are doing surprising things in the area of moral judgement
all the time. In some respects, children often look like
geniuses, making judgements on the basis of rules that they
haven’t been taught. So, I still do believe that the hypothesis of
innate moral knowledge is plausible and worthy of serious
consideration. And I’m excited and intrigued about the fact
that many recent developments in cognitive science appear to
be pointing in this general direction.